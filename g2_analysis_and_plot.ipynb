{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "# Class adapted from: https://github.com/SumeetRohilla/readPTU_FLIM.\n",
    "class PTUreader():\n",
    "    \"\"\" PTUreader() provides the capability to retrieve raw_data from\n",
    "    a PTU file acquired using available PQ TCSPC module in the year 2019.\n",
    "\n",
    "    @params str filename: path + filename\n",
    "    @params bool print_header: True or False\n",
    "    \n",
    "    Output: ptu_read_raw_data(), this function reads single-photon data from the input file.\n",
    "    The output variables contain the followig data:\n",
    "        sync : number of the sync events that preceeded this detection event\n",
    "        tcspc : number of the tcspc-bin of the event\n",
    "        channel : number of the input channel of the event (detector-number)\n",
    "        special : marker event-type (0: photon; else : virtual photon/line_Startmarker/line_Stopmarker/framer_marker)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Global constants\n",
    "    # Define different tag types in header\n",
    "    tag_type = dict(\n",
    "    tyEmpty8      = 0xFFFF0008,\n",
    "    tyBool8       = 0x00000008,\n",
    "    tyInt8        = 0x10000008,\n",
    "    tyBitSet64    = 0x11000008,\n",
    "    tyColor8      = 0x12000008,\n",
    "    tyFloat8      = 0x20000008,\n",
    "    tyTDateTime   = 0x21000008,\n",
    "    tyFloat8Array = 0x2001FFFF,\n",
    "    tyAnsiString  = 0x4001FFFF,\n",
    "    tyWideString  = 0x4002FFFF,\n",
    "    tyBinaryBlob  = 0xFFFFFFFF,\n",
    "    )\n",
    "    \n",
    "    # Dictionary with Record Types format for different TCSPC devices and corresponding T2 or T3 TTTR mode\n",
    "    rec_type = dict(\n",
    "        rtMultiHarpNT3   = 0x00010307,  # (SubID = $00 ,RecFmt: $01) (V1), T-Mode: $03 (T3), HW: $07 (MultiHarp150N)\n",
    "        rtMultiHarpNT2   = 0x00010207,  # (SubID = $00 ,RecFmt: $01) (V1), T-Mode: $02 (T2), HW: $07 (MultiHarp150N)\n",
    "    )\n",
    "\n",
    "    def __init__(self, filename, print_header_data = False):\n",
    "        # Reverse mappins of tag-type and record-type dictionary\n",
    "        self.tag_type_r = {j: k for k, j in self.tag_type.items()}\n",
    "        self.rec_type_r = {j: k for k, j in self.rec_type.items()}\n",
    "        \n",
    "        self.ptu_name = filename\n",
    "        self.print_header = print_header_data\n",
    "        self.ptu_data_string = None\n",
    "        \n",
    "        f = open(self.ptu_name, 'rb')\n",
    "        self.ptu_data_string = f.read()  # ptu_data_string is a string of bytes and reads all file in memory\n",
    "        f.close()\n",
    "        \n",
    "        # Read magic and version of the PTU file\n",
    "        self.magic = self.ptu_data_string[:8].rstrip(b'\\0')\n",
    "        self.version = self.ptu_data_string[8:16].rstrip(b'\\0')\n",
    "        if self.magic != b'PQTTTR':  # Check if the input file is a valid input file\n",
    "            raise IOError(f\"This file is not a valid PTU file. Magic : {self.magic}\")\n",
    "            exit(0)\n",
    "        \n",
    "        self.head = {}\n",
    "        self._ptu_read_head(self.ptu_data_string)  # Read and print header if set True\n",
    "        self._ptu_read_raw_data()  # Read and return raw TTTR data\n",
    "        if self.print_header == True:\n",
    "            return self._print_ptu_head()\n",
    "        return None\n",
    "    \n",
    "    def _ptu_TDateTime_to_time(self, TDateTime):\n",
    "        EpochDiff = 25569  # days between 30/12/1899 and 01/01/1970\n",
    "        SecsInDay = 86400  # number of seconds in a day\n",
    "        return (TDateTime - EpochDiff) * SecsInDay\n",
    "\n",
    "    def _ptu_read_tags(self, ptu_data_string, offset):\n",
    "        # Get the header struct as a tuple\n",
    "        # Struct fields: 32-char string, int32, uint32, int64\n",
    "        tag_struct = struct.unpack('32s i I q', ptu_data_string[offset:offset+48])\n",
    "        offset += 48\n",
    "\n",
    "        # Get the tag name (first element of the tag_struct)\n",
    "        tagName = tag_struct[0].rstrip(b'\\0').decode()\n",
    "        keys = ('idx', 'type', 'value')\n",
    "        tag = {k: v for k, v in zip(keys, tag_struct[1:])}\n",
    "\n",
    "        # Recover the name of the type from tag_dictionary\n",
    "        tag['type'] = self.tag_type_r[tag['type']]\n",
    "        tagStringR='NA'\n",
    "\n",
    "        # Some tag types need conversion to appropriate data format\n",
    "        if tag['type'] == 'tyFloat8':\n",
    "            tag['value'] = np.int64(tag['value']).view('float64')\n",
    "        elif tag['type'] == 'tyBool8':\n",
    "            tag['value'] = bool(tag['value'])\n",
    "        elif tag['type'] == 'tyTDateTime':\n",
    "            TDateTime = np.uint64(tag['value']).view('float64')\n",
    "            t = time.gmtime(self._ptu_TDateTime_to_time(TDateTime))\n",
    "            tag['value'] = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "\n",
    "        # Some tag types have additional data\n",
    "        if tag['type'] == 'tyAnsiString':\n",
    "            try: tag['data'] = ptu_data_string[offset: offset + tag['value']].rstrip(b'\\0').decode()\n",
    "            except: tag['data'] = ptu_data_string[offset: offset + tag['value']].rstrip(b'\\0').decode(encoding  = 'utf-8', errors = 'ignore')\n",
    "            tagStringR = tag['data']\n",
    "            offset += tag['value']\n",
    "        elif tag['type'] == 'tyFloat8Array':\n",
    "            tag['data'] = np.frombuffer(ptu_data_string, dtype='float', count=tag['value']/8)\n",
    "            offset += tag['value']\n",
    "        elif tag['type'] == 'tyWideString':\n",
    "            # WideString default encoding is UTF-16.\n",
    "            tag['data'] = ptu_data_string[offset: offset + tag['value']*2].decode('utf16')\n",
    "            tagStringR=tag['data']\n",
    "            offset += tag['value']\n",
    "        elif tag['type'] == 'tyBinaryBlob':\n",
    "            tag['data'] = ptu_data_string[offset: offset + tag['value']]\n",
    "            offset += tag['value']\n",
    "\n",
    "        tagValue  = tag['value']\n",
    "        return tagName, tagValue, offset, tagStringR\n",
    "    \n",
    "    def _ptu_read_head(self, ptu_data_string):\n",
    "        offset         = 16\n",
    "        FileTagEnd     = 'Header_End' \n",
    "        tag_end_offset = ptu_data_string.find(FileTagEnd.encode())\n",
    "        tagName, tagValue, offset, tagString  = self._ptu_read_tags(ptu_data_string, offset)\n",
    "        self.head[tagName] = tagValue\n",
    "        while tagName != FileTagEnd:\n",
    "                tagName, tagValue, offset, tagString = self._ptu_read_tags(ptu_data_string, offset)\n",
    "                if tagString=='NA': self.head[tagName] = tagValue\n",
    "                else: self.head[tagName] = tagString\n",
    "        # End of Header file and beginning of TTTR data\n",
    "        self.head[FileTagEnd] = offset\n",
    "\n",
    "    def _print_ptu_head(self): \n",
    "        ''' Print \"head\" dictionary '''     \n",
    "        print(\"{:<30} {:8}\".format('Head ID','Value'))\n",
    "        for keys in self.head:\n",
    "            val = self.head[keys] \n",
    "            print(\"{:<30} {:<8}\".format(keys, val))     \n",
    "    \n",
    "    def _ptu_read_raw_data(self):\n",
    "        ''' This function reads single-photon data from the file 's'\n",
    "        Returns:\n",
    "        sync    : number of the sync events that preceeded this detection event\n",
    "        tcspc   : number of the tcspc-bin of the event\n",
    "        chan    : number of the input channel of the event (detector-number)\n",
    "        special : indicator of the event-type (0: photon; else : virtual photon)\n",
    "        num     : counter of the records that were actually read\n",
    "        '''\n",
    "        record_type = self.rec_type_r[self.head['TTResultFormat_TTTRRecType']]\n",
    "        num_T3records = self.head['TTResult_NumberOfRecords']\n",
    "\n",
    "        # Read all T3 records in memory\n",
    "        t3records = np.frombuffer(self.ptu_data_string, dtype='uint32', count=num_T3records, offset= self.head['Header_End'])\n",
    "        # Clear ptu string data from memory and delete it's existence\n",
    "        del self.ptu_data_string\n",
    "        \n",
    "        # Next is to do T3Records formatting according to Record_type\n",
    "        if record_type in ['rtMultiHarpNT3']:\n",
    "            print('TCSPC Hardware: {}'.format(record_type[2:]))\n",
    "            WRAPAROUND = 1024                                                   # After this sync counter will overflow\n",
    "            sync       = np.bitwise_and(t3records, 1023)                        # Lowest 10 bits\n",
    "            tcspc      = np.bitwise_and(np.right_shift(t3records, 10), 32767)   # Next 15 bits, dtime can be obtained from header\n",
    "            chan       = np.bitwise_and(np.right_shift(t3records, 25), 63)      # Next 8 bits \n",
    "            special    = np.bitwise_and(t3records,2147483648)>0                 # Last bit for special markers\n",
    "            index      = (special*1)*((chan==63)*1)                             # Find overflow locations\n",
    "            special    = (special*1)*chan\n",
    "        elif record_type in ['rtMultiHarpNT2']:\n",
    "            print('TCSPC Hardware: {}'.format(record_type[2:]))\n",
    "            WRAPAROUND = 33554432                                               # After this sync counter will overflow\n",
    "            sync       = np.bitwise_and(t3records, 33554431)                    # Lowest 25 bits\n",
    "            chan       = np.bitwise_and(np.right_shift(t3records, 25), 63)      # Next 6 bits \n",
    "            tcspc      = np.bitwise_and(chan, 15)                               \n",
    "            special    = np.bitwise_and(np.right_shift(t3records, 31), 1)       # Last bit for special markers\n",
    "            index      = (special*1) * ((chan==63)*1)                           # Find overflow locations\n",
    "            special    = (special*1)*chan\n",
    "        else:\n",
    "            print('Illegal RecordType!')\n",
    "            exit(0)\n",
    "\n",
    "        # Fill in the correct sync values for overflow location    \n",
    "        if record_type in ['rtMultiHarpNT3']:\n",
    "            sync = sync + (WRAPAROUND*np.cumsum(index*sync)) # For overflow corrections \n",
    "        else:\n",
    "            sync = sync + (WRAPAROUND*np.cumsum(index)) # correction for overflow to sync varibale\n",
    "        sync     = np.delete(sync, np.where(index == 1), axis = 0)\n",
    "        tcspc    = np.delete(tcspc, np.where(index == 1), axis = 0)\n",
    "        chan     = np.delete(chan, np.where(index == 1), axis = 0)\n",
    "        special  = np.delete(special, np.where(index == 1), axis = 0)\n",
    "        del index\n",
    "\n",
    "        # Convert to appropriate data type to save memory\n",
    "        self.sync    = sync.astype(np.uint64, copy=False)\n",
    "        self.tcspc   = tcspc.astype(np.uint16, copy=False)\n",
    "        self.channel = chan.astype(np.uint8,  copy=False)\n",
    "        self.special = special.astype(np.uint8, copy=False)\n",
    "        print(\"Raw Data has been Read!\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cba067",
   "metadata": {},
   "source": [
    "## Import file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e375e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filename = r'path\\filename.ptu'\n",
    "try: \n",
    "    with open(filename): pass\n",
    "    print('Data file found, you can proceed.')\n",
    "except IOError:\n",
    "    print(f'Beware: Data file not found, please check the filename (current value: {filename})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79411bb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ptu_file = PTUreader(filename, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1250569",
   "metadata": {},
   "source": [
    "### TIMESTAMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d06366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sync times in second units:\n",
    "true_sync = ptu_file.sync * ptu_file.head[\"MeasDesc_GlobalResolution\"] * 1e12\n",
    "\n",
    "# tcspc times in second units:\n",
    "true_tcspc = np.zeros((ptu_file.tcspc.size,), dtype=np.int64)\n",
    "for i in range(ptu_file.tcspc.size):\n",
    "    true_tcspc[i] = ptu_file.tcspc[i] * 10\n",
    "\n",
    "# get the 'true' timestamp:\n",
    "timestamp_temp = true_sync + true_tcspc\n",
    "\n",
    "# ===============================\n",
    "\n",
    "# get the timestamps packet as int for cython code (small info loss):\n",
    "timestamp_packet = np.zeros((ptu_file.sync.size,), dtype=np.int64)\n",
    "for i in range(ptu_file.sync.size):\n",
    "    timestamp_packet[i] = int(timestamp_temp[i])\n",
    "\n",
    "# get the channel packet\n",
    "channel_packet = np.zeros((ptu_file.sync.size,), dtype=np.int8)\n",
    "for i in range(ptu_file.sync.size):\n",
    "    channel_packet[i] = ptu_file.channel[i]\n",
    "\n",
    "timestamp_packet.dtype, channel_packet.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_channel = 0\n",
    "stop_channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a29dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "\n",
    "ax.plot(timestamp_packet[channel_packet==stop_channel] * 1e-6, \n",
    "        channel_packet[channel_packet==stop_channel], color='blue', lw=0, marker='+')\n",
    "ax.plot(timestamp_packet[channel_packet==start_channel] * 1e-6, \n",
    "        channel_packet[channel_packet==start_channel], color='red', lw=0, marker='+')\n",
    "\n",
    "ax.set_xlabel(\"Time [Âµs]\")\n",
    "ax.set_ylabel(\"Channel\")\n",
    "ax.set_xlim(0, None)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5becb6e",
   "metadata": {},
   "source": [
    "## Calculate g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9eb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2_time_window_s = 10e-3\n",
    "g2_time_bin_s = 10e-9\n",
    "\n",
    "time_window_ps = int(g2_time_window_s*1e12)\n",
    "time_bin_ps = int(g2_time_bin_s*1e12)\n",
    "number_of_bin = int(time_window_ps/time_bin_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "import cython\n",
    "@cython.cdivision(True)\n",
    "@cython.boundscheck(False) \n",
    "@cython.wraparound(False)\n",
    "\n",
    "def compute_g2(long long[:] timestamp_packet not None, \n",
    "               signed char [:] channel_packet not None,\n",
    "               int start_channel,\n",
    "               int stop_channel,\n",
    "               long long time_window_ps,\n",
    "               long long time_bin_ps):\n",
    "    \n",
    "    cdef int number_of_bin, length, length_minus_1, i, j, index\n",
    "    cdef long long delay, start\n",
    "    \n",
    "    number_of_bin = int(time_window_ps/time_bin_ps)\n",
    "    histogram_before = np.zeros(number_of_bin, dtype=np.int32)\n",
    "    histogram_after = np.zeros(number_of_bin, dtype=np.int32)\n",
    "    \n",
    "    cdef int[:] view_histogram_before = histogram_before\n",
    "    cdef int[:] view_histogram_after = histogram_after\n",
    "    \n",
    "    length = len(timestamp_packet)\n",
    "    i = 0\n",
    "    \n",
    "    while i < length:\n",
    "        if channel_packet[i] == start_channel:\n",
    "            start = timestamp_packet[i]\n",
    "            # Positive times\n",
    "            j = i+1\n",
    "            while j < length:\n",
    "                delay = timestamp_packet[j] - start\n",
    "                if delay >= time_window_ps:\n",
    "                    break\n",
    "                if channel_packet[j] == stop_channel:\n",
    "                    index = delay // time_bin_ps\n",
    "                    view_histogram_after[index] += 1\n",
    "                j += 1\n",
    "            # Negatives times\n",
    "            j = i-1\n",
    "            while j >= 0:\n",
    "                delay = start - timestamp_packet[j]\n",
    "                if delay >= time_window_ps:\n",
    "                    break\n",
    "                if channel_packet[j] == stop_channel:\n",
    "                    index = delay // time_bin_ps\n",
    "                    view_histogram_before[index] += 1\n",
    "                j -= 1\n",
    "        i += 1\n",
    "    return np.concatenate([np.flip(histogram_before), histogram_after])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d79d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = compute_g2(timestamp_packet, channel_packet, start_channel, stop_channel, time_window_ps, time_bin_ps)\n",
    "histogram = np.zeros(2*number_of_bin, dtype=np.int32)\n",
    "histogram += g2\n",
    "histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3cfc58",
   "metadata": {},
   "source": [
    "## PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ab760",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trace = (np.arange(len(histogram)) - int(len(histogram)/2)) * g2_time_bin_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715c20e",
   "metadata": {},
   "source": [
    "### Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc92ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_count, stop_count = 0, 0\n",
    "start_count += (channel_packet == start_channel).sum()\n",
    "stop_count += (channel_packet == stop_channel).sum()\n",
    "\n",
    "time_stop_ms = ptu_file.head[\"MeasDesc_AcquisitionTime\"]\n",
    "time_stop_ps = time_stop_ms * 1e9\n",
    "time_start_ps = 0\n",
    "\n",
    "duration = (time_stop_ps - time_start_ps) / 1e12\n",
    "\n",
    "average_stop = stop_count / duration\n",
    "normalization_g2 = start_count * average_stop * g2_time_bin_s\n",
    "histogram_norm = histogram / normalization_g2\n",
    "\n",
    "print(f\"start_count: {start_count}, stop_count: {stop_count}, time_bin: {g2_time_bin_s}s , acq_time: {duration}s, \\\n",
    "norm: {normalization_g2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2aaf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_to_plot, y_to_plot = x_trace, histogram_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a079c2e",
   "metadata": {},
   "source": [
    "### Rebin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebin functions from : https://pypi.org/project/data-analysis-tools/\n",
    "def rebin(data, rebin_ratio, do_average=False):\n",
    "    \"\"\" Rebin a 1D array the good old way.\n",
    "    @param 1d numpy array data : The data to rebin\n",
    "    @param int rebin_ratio: The number of old bin per new bin\n",
    "    @return 1d numpy array : The array rebinned\n",
    "    The last values may be dropped if the sizes do not match. \"\"\"\n",
    "    \n",
    "    rebin_ratio = int(rebin_ratio)\n",
    "    length = (len(data) // rebin_ratio) * rebin_ratio\n",
    "    data = data[0:length]\n",
    "    data = data.reshape(length//rebin_ratio, rebin_ratio)\n",
    "    if do_average :\n",
    "        data_rebinned = data.mean(axis=1)\n",
    "    else :\n",
    "        data_rebinned = data.sum(axis=1)\n",
    "    return data_rebinned\n",
    "\n",
    "def decimate(data, decimation_ratio):\n",
    "    \"\"\" Decimate a 1D array . This means some value are dropped, not averaged\n",
    "    @param 1d numpy array data : The data to decimated\n",
    "    @param int decimation_ratio: The number of old value per new value\n",
    "    @return 1d numpy array : The array decimated. \"\"\"\n",
    "    \n",
    "    decimation_ratio = int(decimation_ratio)\n",
    "    length = (len(data) // decimation_ratio) * decimation_ratio\n",
    "    data_decimated = data[:length:decimation_ratio]\n",
    "    return data_decimated\n",
    "\n",
    "def rebin_xy(x, y, ratio=1, do_average=True):\n",
    "    \"\"\" Helper method to decimate x and rebin y, with do_average True as default. \"\"\"\n",
    "    return decimate(x, ratio), rebin(y, ratio, do_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_to_plot, y_to_plot = rebin_xy(x_trace, histogram_norm, ratio=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b53b62",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40540989",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "label = f'$g^2_{{ ({start_channel}, {stop_channel}) }}$'\n",
    "\n",
    "ax.plot(x_to_plot*1e6, y_to_plot, label=label, color='dodgerblue', marker='+', lw=0)\n",
    "\n",
    "ax.set_xlabel('Time [us]', fontsize=18)\n",
    "ax.set_ylabel('$g^2(\\\\tau)$', fontsize=18)\n",
    "\n",
    "# ax.axhline(1, color='black', lw=1, ls='--')\n",
    "ax.axhline(histogram_norm.mean(), color='red', lw=1, ls='--', label='Mean value')\n",
    "ax.axvline(0, color='green', lw=1, ls='--')\n",
    "\n",
    "# ax.set_xlim(-10, 10)\n",
    "ax.set_ylim(0, 1.5)\n",
    "ax.legend(loc='lower left', fontsize=12.0)\n",
    "\n",
    "# fig.dpi = 100\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
